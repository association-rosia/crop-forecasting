{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19c38328-175d-439a-b498-7ece078342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bac025-1350-43f8-a007-7b885283a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'augment_10_5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf1fed-f9c8-4eac-8ac9-be9b48c4c1b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create m inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbc8872-126b-438d-894b-d7b98f7c7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_path = f'../../data/raw/weather'\n",
    "chau_phu = pd.read_csv(f'{weather_path}/Chau Phu.csv')\n",
    "chau_thanh = pd.read_csv(f'{weather_path}/Chau Thanh.csv')\n",
    "thoai_son = pd.read_csv(f'{weather_path}/Thoai Son.csv')\n",
    "weather_df = pd.concat([chau_phu, chau_thanh, thoai_son])\n",
    "\n",
    "# remove NULL columns\n",
    "null_cols = ['preciptype', 'snow', 'snowdepth', 'windgust', 'severerisk']\n",
    "weather_df = weather_df.drop(columns=null_cols)\n",
    "\n",
    "# remove useless columns \n",
    "useless_cols = ['conditions', 'description', 'icon', 'stations', 'sunrise', 'sunset'] \n",
    "weather_df = weather_df.drop(columns=useless_cols)\n",
    "\n",
    "# preprocess come columns\n",
    "weather_df['name'] = weather_df['name'].apply(lambda x: x.replace(' ', '_'))\n",
    "weather_df['datetime'] = weather_df['datetime'].apply(lambda x: f'{x.split(\"-\")[2]}-{x.split(\"-\")[1]}-{x.split(\"-\")[0]}')\n",
    "\n",
    "m_columns = [e for e in weather_df.columns if e not in ['name', 'datetime']]\n",
    "m_scaler = StandardScaler()\n",
    "m_scaler.fit(weather_df[m_columns])\n",
    "weather_df[m_columns] = m_scaler.transform(weather_df[m_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839fe59-1735-408f-8827-c8028e388810",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create s inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18150dd3-7e98-4283-9df6-4598d81fa8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vi_path = f'../../data/processed/{FOLDER}/train_filter_vi_fill.nc'\n",
    "train_xdf = xr.open_dataset(train_vi_path)\n",
    "train_xdf = train_xdf.drop(['time', 'Season(SA = Summer Autumn, WS = Winter Spring)'])\n",
    "train_vi_df = train_xdf.to_dataframe().reset_index()\n",
    "train_vi_df = train_vi_df.drop(columns='ts_id')\n",
    "\n",
    "useless_cols = ['Rice Crop Intensity(D=Double, T=Triple)', 'Field size (ha)', 'Rice Yield (kg/ha)']\n",
    "train_vi_df = train_vi_df.drop(columns=useless_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0f3ffcc-a9ad-4359-ae14-d07b6ce110d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_dev                    23\n",
       "District              Thoai_Son\n",
       "Date of Harvest      28-07-2022\n",
       "Latitude              10.676956\n",
       "Longitude            105.424059\n",
       "ndvi                   0.925801\n",
       "savi                   1.462852\n",
       "evi                 133458.4375\n",
       "rep                87961.242188\n",
       "osavi                   0.92577\n",
       "rdvi                  73.268044\n",
       "mtvi1               9480.698242\n",
       "lswi                   0.982012\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vi_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21920db2-1aea-4caa-bede-d2fa29e2049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vi_path = f'../../data/processed/{FOLDER}/test_filter_vi_fill_smooth.nc'\n",
    "test_xdf = xr.open_dataset(test_vi_path)\n",
    "test_xdf = test_xdf.drop(['time', 'Season(SA = Summer Autumn, WS = Winter Spring)'])\n",
    "test_vi_df = test_xdf.to_dataframe().reset_index()\n",
    "test_vi_df = test_vi_df.drop(columns='ts_id')\n",
    "\n",
    "useless_cols = ['Rice Crop Intensity(D=Double, T=Triple)', 'Field size (ha)', 'Predicted Rice Yield (kg/ha)']\n",
    "test_vi_df = test_vi_df.drop(columns=useless_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4adacbe2-33e0-4c4d-a22c-e1fcb5a461b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m s_columns \u001b[38;5;241m=\u001b[39m [e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m train_vi_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m remove_columns]\n\u001b[1;32m      4\u001b[0m s_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 5\u001b[0m \u001b[43ms_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_vi_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms_columns\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m train_vi_df[s_columns] \u001b[38;5;241m=\u001b[39m s_scaler\u001b[38;5;241m.\u001b[39mtransform(train_vi_df[s_columns])\n\u001b[1;32m      7\u001b[0m test_vi_df[s_columns] \u001b[38;5;241m=\u001b[39m s_scaler\u001b[38;5;241m.\u001b[39mtransform(test_vi_df[s_columns])\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/utils/validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m         )\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 899\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "remove_columns = ['District', 'Latitude', 'Longitude', 'Date of Harvest', 'date']\n",
    "s_columns = [e for e in train_vi_df.columns if e not in remove_columns]\n",
    "\n",
    "s_scaler = StandardScaler()\n",
    "s_scaler.fit(train_vi_df[s_columns])\n",
    "train_vi_df[s_columns] = s_scaler.transform(train_vi_df[s_columns])\n",
    "test_vi_df[s_columns] = s_scaler.transform(test_vi_df[s_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f742b7-f1f0-4ccc-86ad-5e8185f5ee02",
   "metadata": {},
   "source": [
    "# Create g inputs + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f088bc-1c04-4b93-ae62-6e36074f9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../../data/raw/train.csv'\n",
    "test_path = '../../data/raw/test.csv'\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "crop_intensity = 'Rice Crop Intensity(D=Double, T=Triple)'\n",
    "train_df[crop_intensity] = train_df[crop_intensity].replace('D', 0)\n",
    "train_df[crop_intensity] = train_df[crop_intensity].replace('T', 1)\n",
    "test_df[crop_intensity] = test_df[crop_intensity].replace('D', 0)\n",
    "test_df[crop_intensity] = test_df[crop_intensity].replace('T', 1)\n",
    "\n",
    "g_columns = [crop_intensity, 'Field size (ha)']\n",
    "g_scaler = StandardScaler()\n",
    "g_scaler.fit(train_df[g_columns])\n",
    "train_df[g_columns] = g_scaler.transform(train_df[g_columns])\n",
    "test_df[g_columns] = g_scaler.transform(test_df[g_columns])\n",
    "\n",
    "label_scaler = MinMaxScaler()\n",
    "train_df['Rice Yield (kg/ha)'] = label_scaler.fit_transform(train_df[['Rice Yield (kg/ha)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b3412-fd99-49b0-85fa-668163f03658",
   "metadata": {},
   "source": [
    "# Save all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d2c87f-d05e-459b-89d1-c34863d2b04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/processed/lstm/fixed_0-00146/label_scaler.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.to_csv(f'../../data/processed/lstm/{FOLDER}/weather_df.csv', index=False)\n",
    "\n",
    "train_df.to_csv(f'../../data/processed/lstm/{FOLDER}/train_df.csv', index=False)\n",
    "train_vi_df.to_csv(f'../../data/processed/lstm/{FOLDER}/train_vi.csv', index=False)\n",
    "\n",
    "test_df.to_csv(f'../../data/processed/lstm/{FOLDER}/test_df.csv', index=False)\n",
    "test_vi_df.to_csv(f'../../data/processed/lstm/{FOLDER}/test_vi.csv', index=False)\n",
    "\n",
    "joblib.dump(label_scaler, f'../../data/processed/lstm/{FOLDER}/label_scaler.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
