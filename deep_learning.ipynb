{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native library\n",
    "from os.path import join\n",
    "\n",
    "# Data management\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Data prepocessing\n",
    "from src.data.preprocessing import Smoother\n",
    "from src.data.process_data import (merge_satellite, compute_vi, add_observation, \n",
    "                                   add_weather, statedev_fill, features_modification,\n",
    "                                   scale_data, create_id)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.models.trainer import Trainer\n",
    "from src.models.model import CustomModel\n",
    "from src.models.train import get_device\n",
    "from src.models.dataloader import get_dataloaders, DataLoader\n",
    "\n",
    "from src.constants import FOLDER, S_COLUMNS, TARGET\n",
    "from utils import ROOT_DIR\n",
    "\n",
    "TEST = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = join(ROOT_DIR, \"data\", \"processed\", FOLDER)\n",
    "file_name = \"train.nc\"\n",
    "\n",
    "xds = merge_satellite(file_name)\n",
    "xds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and Merge EY data to Satellite Dataset\n",
    "xds = add_observation(xds, TEST)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and Merge Weather data to Satellite & EY Dataset\n",
    "xds = add_weather(xds)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute vegetable indices\n",
    "xds = compute_vi(xds)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing vegetable indice and replace abnormal values\n",
    "xds = statedev_fill(xds)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth variable\n",
    "xds = Smoother(mode='savgol').transform(xds)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "xds = features_modification(xds, TEST)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "xds = scale_data(xds, processed_dir, TEST)\n",
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an id for each line\n",
    "xds = create_id(xds)\n",
    "xds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model() -> tuple[dict, DataLoader, DataLoader]:\n",
    "    \"\"\" Init W&B logger and get the model config from W&B sweep config yaml file\n",
    "        + get the training and validation dataloaders.\n",
    "\n",
    "    :return: the model config and the training and validation dataloaders\n",
    "    :rtype: (dict, DataLoader, DataLoader)\n",
    "    \"\"\"\n",
    "\n",
    "    epochs = 25\n",
    "    lstm_dropout = .5\n",
    "    cnn_dropout = .1\n",
    "    fc_dropout = .4\n",
    "    criterion = 'MSELoss'\n",
    "    optimizer = 'AdamW'\n",
    "    batch_size = 16\n",
    "    learning_rate = .001\n",
    "    scheduler_patience = 4\n",
    "    c_out_in_features_1 = 150\n",
    "    c_out_in_features_2 = 150\n",
    "    m_num_layers = 2\n",
    "    s_num_layers = 2\n",
    "    s_hidden_size = 150\n",
    "    m_hidden_size = 150\n",
    "    train_dataloader, val_dataloader, _ = get_dataloaders(batch_size, 0.2, get_device())\n",
    "    first_row = train_dataloader.dataset[0]\n",
    "    \n",
    "    c_in_features = s_hidden_size - 2 + m_hidden_size - 2 + first_row['g_input'].shape[0]\n",
    "\n",
    "    config = {\n",
    "        'batch_size': batch_size,\n",
    "        's_hidden_size': s_hidden_size,\n",
    "        's_num_layers': s_num_layers,\n",
    "        'm_hidden_size': m_hidden_size,\n",
    "        'm_num_layers': m_num_layers,\n",
    "        'learning_rate': learning_rate,\n",
    "        'scheduler_patience': scheduler_patience,\n",
    "        'lstm_dropout': lstm_dropout,\n",
    "        'cnn_dropout': cnn_dropout,\n",
    "        'fc_dropout': fc_dropout,\n",
    "        'epochs': epochs,\n",
    "        'optimizer': optimizer,\n",
    "        'criterion': criterion,\n",
    "        's_num_features': first_row['s_input'].shape[1],\n",
    "        'm_num_features': first_row['m_input'].shape[1],\n",
    "        'g_in_features': first_row['g_input'].shape[0],\n",
    "        'c_in_features': c_in_features,\n",
    "        'c_out_in_features_1': c_out_in_features_1,\n",
    "        'c_out_in_features_2': c_out_in_features_2,\n",
    "        'train_size': len(train_dataloader),\n",
    "        'val_size': len(val_dataloader),\n",
    "    }\n",
    "\n",
    "    return config, train_dataloader, val_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Train using the script to avoid tqdm bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# get the device\n",
    "device = get_device()\n",
    "\n",
    "# init W&B logger and get the model config from W&B sweep config yaml file\n",
    "# + get the training and validation dataloaders\n",
    "config, train_dataloader, val_dataloader = init_model()\n",
    "\n",
    "# init the model\n",
    "model = CustomModel(config)\n",
    "model.to(device)\n",
    "\n",
    "# init the loss, optimizer and learning rate scheduler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                        patience=config['scheduler_patience'],\n",
    "                                                        verbose=True)\n",
    "\n",
    "train_config = {\n",
    "    'model': model,\n",
    "    'train_dataloader': train_dataloader,\n",
    "    'val_dataloader': val_dataloader,\n",
    "    'epochs': config['epochs'],\n",
    "    'criterion': criterion,\n",
    "    'optimizer': optimizer,\n",
    "    'scheduler': scheduler,\n",
    "}\n",
    "\n",
    "# init the trainer\n",
    "trainer = Trainer(**train_config)\n",
    "\n",
    "# train the model\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "06b7480f36a42d8bbade06fc4149129af8b8df398eea6bf44659ace11c5fcf70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
